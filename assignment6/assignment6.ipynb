{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Landon Buell\n",
    "Marek Petrik\n",
    "CS 750.01\n",
    "21 March 2020\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 [33%] \n",
    "In this problem, we will establish some basic properties of vectors and linear functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. The L2 norm of a vector measures the length (size) of a vector. The norm for a vector x of size n is deÔ¨Åned as: \n",
    "$$ ||x||_2 = \\sqrt{\\sum_{i=1}^{n}x_i^2} $$\n",
    "#### Show that the norm can be expressed as the following quadratic expression: \n",
    "$$ ||x||_2^2 = x^T x $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the definition of the $L_2$ norm above, we can compute the square of it. THis removes the radical, and then the norm, squared is just the sum of all elements in the vector $x$, squared. Thus:\n",
    "$$ ||x||_2^2 = \\sum_{i=1}^{n}x_i^2 $$\n",
    "We can compare this to the vector $x$, by itself, it is a column vector with $n$ entres, shaped $1 \\times n$. The corresponding transpose, $x^T$, then also has $n$ elements, but is a row vector containing the same elements, shaped $m \\times 1$. When computing their matrix multiplication, or in this case, dot product, $x^T x$. The result is the $i$-th element in each array multiplied by the same element in the other array, and them summed. Given that they are just mutual transposes, corresponding elemtns are identitcial so: \n",
    "$$x^T_i = x_i \\rightarrow x^T_i x_i = x_i^2 $$\n",
    "Finally, summing over all elements in the arrays just produces the result:\n",
    "$$ ||x||_2^2 = \\sum_{i=1}^{n}x_i^2 $$\n",
    "Which we have shown above to be equivalent to the square of the $L_2$ norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Let $a$ and $x$ be vectors of size $n = 3$ and consider the following linear function $f(x)= a^T x$. Show that the gradient of $f$ is: $\\nabla_x f(x) = a$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When evaluating $f(x) = a^T x$, we see that it becomes the dot product of vectors $a$ and $x$:\n",
    "$$a^T x = a_1 x_1 + a_2 x_2 + a_3 x_3 $$\n",
    "So, if we take the gradient of $f(x)$, with respect to each elment in the $x$ vector:\n",
    "$$\\nabla_x f(x) = \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial x1}  \\\\\n",
    "\\frac{\\partial f}{\\partial x2}  \\\\\n",
    "\\frac{\\partial f}{\\partial x3} \n",
    "\\end{bmatrix} $$\n",
    "Using rules of partial differntiation from calculus 3, we can then evaluate this gradient to be:\n",
    "$$\\nabla_x f(x) = \n",
    "\\begin{bmatrix}\n",
    "a_1 \\\\ a_2 \\\\ a_3 \n",
    "\\end{bmatrix}$$\n",
    "Which is indentically the vector $a$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Let $A$ be a symmetric matrix of size $3 \\times 3$ and consider the following quadratic function $f(x) = x^T Ax$. Show that the gradient of $f$ is: $\\nabla_x f(x) = 2Ax$. A matrix is symmetric if $A_{ij} = A_{ji}$ for all $i$ and $j$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluatiing out $f(x)$ allows for:\n",
    "$$ x^T Ax = \\Big[x_1 , x_2 , x_3 \\Big] \n",
    "\\begin{bmatrix}\n",
    "A_{11}x_1 + A_{12}x_2 + A_{13}x_3 , \\\\\n",
    "A_{21}x_1 + A_{22}x_2 + A_{23}x_3 , \\\\\n",
    "A_{31}x_1 + A_{32}x_2 + A_{33}x_3\n",
    "\\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 [34%] \n",
    "### Hint: You can follow the slides from the March 4th class, or the LAR reference from the class website. See the class website for some recommended linear algebra references. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 [33%] \n",
    "### Using the MNIST dataset, which we used already in Assignment 2, compare whether boosting, bagging, and random forests work the best. You may may want to use only a subset of the data. Optional: Use xgboost (also available for Python) to see whether the results are better than other boosting methods. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
