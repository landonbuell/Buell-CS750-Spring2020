{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Landon Buell\n",
    "Marek Petrik\n",
    "CS 750.01\n",
    "5 Feb 2020\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 [30%]\n",
    "#### This problem examines the use and assumptions of Linear Discrimiant Analysis (LDA) and Quadratic Discrimiant Analysis (QDA). We will be using the dataset Default from ISLR. \n",
    "\n",
    "I loaded the datset into R, and the rewrote it as a CSV to use in python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   default  student      balance        income\n",
       "0      0.0      0.0   729.526495  44361.625074\n",
       "1      0.0      1.0   817.180407  12106.134700\n",
       "2      0.0      0.0  1073.549164  31767.138947\n",
       "3      0.0      0.0   529.250605  35704.493935\n",
       "4      0.0      0.0   785.655883  38463.495879"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in data from CSV and make all numeric\n",
    "default = pd.read_csv(\"Default.txt\",sep=\",\",header=0,usecols=[1,2,3,4])\n",
    "\n",
    "default = default.replace(\"No\",0)\n",
    "default = default.replace(\"Yes\",1)\n",
    "default = default.astype(float)\n",
    "\n",
    "default.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Split the data into a training set (70%) and a test set (30%). Then compare the classiﬁcation error of LDA, QDA, and logistic regression when predicting default as a function of features of your choice. Which method appears to work best? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Disc. Analysis Classification Error: 0.9756666666666667\n",
      "Quadratic Disc. Analysis Classification Error: 0.9753333333333334\n",
      "Logistic Regression Classification Error: 0.9706666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Landon\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data set into train & test\n",
    "y = default['default'].astype(int)\n",
    "X = default[['student','balance','income']]\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(X,y,test_size=0.3)\n",
    "\n",
    "# Create linear disc. Classifier instance\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "LDA_CLF = LDA()\n",
    "LDA_CLF.fit(xtrain,ytrain)\n",
    "LDA_pred = LDA_CLF.predict(xtest)\n",
    "\n",
    "# Create Quadratic Disc. Classifier instance\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "QDA_CLF = QDA()\n",
    "QDA_CLF.fit(xtrain,ytrain)\n",
    "QDA_pred = QDA_CLF.predict(xtest)\n",
    "\n",
    "# Create Logstic Regression \n",
    "from sklearn.linear_model import LogisticRegression as LRC\n",
    "LRC_CLF = LRC()\n",
    "LRC_CLF.fit(xtrain,ytrain)\n",
    "LRC_pred = LRC_CLF.predict(xtest)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "LDA_score = accuracy_score(ytest,LDA_pred)\n",
    "QDA_score = accuracy_score(ytest,QDA_pred)\n",
    "LRC_score = accuracy_score(ytest,LRC_pred)\n",
    "\n",
    "\n",
    "print(\"Linear Disc. Analysis Classification Error:\",LDA_score)\n",
    "print(\"Quadratic Disc. Analysis Classification Error:\",QDA_score)\n",
    "print(\"Logistic Regression Classification Error:\",LRC_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Report the confusion table for each classiﬁcation method. Make sure to label which dimension is the predicted class and which one is the true class. What do you observe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Disc. Analysis Confusion Matrix:\n",
      "[[2905    8]\n",
      " [  65   22]]\n",
      "Quadratic Disc. Analysis Confusion Matrix:\n",
      "[[2902   11]\n",
      " [  63   24]]\n",
      "Logisitc Regression Confusion Matrix:\n",
      "[[2912    1]\n",
      " [  87    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Linear Disc. Analysis Confusion Matrix:\")\n",
    "LDA_confmat = confusion_matrix(ytest,LDA_pred)\n",
    "print(LDA_confmat)\n",
    "\n",
    "print(\"Quadratic Disc. Analysis Confusion Matrix:\")\n",
    "QDA_confmat = confusion_matrix(ytest,QDA_pred)\n",
    "print(QDA_confmat)\n",
    "\n",
    "print(\"Logisitc Regression Confusion Matrix:\")\n",
    "LRC_confmat = confusion_matrix(ytest,LRC_pred)\n",
    "print(LRC_confmat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each confusion matrix has a string entry at index (1,1) - the True Positive entry. This means that It is excellent at correctly identifying those who belong into class '0': i.e. those who will NOT default on their loans. However, entry (2,2) seems to be very weak, this means that each method is poor at identifying any instance in class \"1\": those who did default on their loans. Furthermore, the entry (2,1) is generally much stronger, indicating that that model predicted the person would not default, even though they did. We usually want a confusion matrix with a strong main diagonal and weaker off-diagonals. These matricies do not grant us that so well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Are the LDA assumptions satisﬁed when predicting default as a function of balance only (i.e default ~ balance)? You can use qqnorm and qqline to examine whether the conditional class distributions are normally distributed. Also examine standard deviations of the class distributions. Are the QDA assumptions satisﬁed? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Would you ever want to use LDA in place of QDA even when you suspect that some of the assumptions are violated (e.g. diﬀerent conditional standard deviations) for LDA? Hint: Check out TidyVerse for a collection of packages that can help with data manipulation. And see the Rstudio cheatsheets for a convenient and concise reference to the methods. This is entirely optional!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 [30%] \n",
    "#### Using the MNIST dataset, ﬁt classiﬁcation models in order to predict the digit 1 (vs all others).\n",
    "\n",
    "1. Compare the classiﬁcation error for each one of these methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'details', 'categories', 'url'])\n"
     ]
    }
   ],
   "source": [
    "# load in MNIST dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784',version=1)\n",
    "print(mnist.keys())\n",
    "X,y = mnist['data'],mnist['target'].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train-test sets\n",
    "xtrain,xtest,ytrain,ytest = X[:60000],X[60000:],y[:10000],y[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. K-NN (with 2 reasonable choices of k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. LDA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
