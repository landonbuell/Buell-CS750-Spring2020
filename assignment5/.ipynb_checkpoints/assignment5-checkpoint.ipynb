{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Landon Buell\n",
    "Marek Petrik\n",
    "CS 750.01\n",
    "26 Feb 2020\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 [25%] \n",
    "### It is mentioned in Chapter 7 of ISL that a cubic regression spline with one knot at ξ can be obtained using a basis of the form $x$, $x^2$, $x^3$, $[x−\\xi]^3_+$, where $[x−\\xi]^3_+ = (x−\\xi)^3$ if $x > \\xi$ and equals 0 otherwise. We will now show that a function of the form \n",
    "$$f(x) = \\beta_0 + \\beta_1x + \\beta_2x^2 +\\beta_3x^3 + \\beta_4[x−\\xi]^3_+ $$\n",
    "\n",
    "### is indeed a cubic regression spline, regardless of the values of $\\beta_0$,$\\beta_1$,$\\beta_2$, $\\beta_3$,$\\beta_4$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Find a cubic polynomial\n",
    "$$ f_1(x)= a_1 +b_1x + c_1x^2 +d_1x^3 $$ \n",
    "#### such that $f(x)= f_1(x)$ for all $x \\leq \\xi$. Express $a_1$,$b_1$,$c_1$,$d_1$ in terms of $\\beta_0$,$\\beta_1$,$\\beta_2$, $\\beta_3$,$\\beta_4$.. \n",
    "\n",
    "The values of each coefficient are found from the corresponding order of the polynomial. Thus: \n",
    "$$ a_1 = \\beta_0 , b_1 = \\beta_1 , c_1 = \\beta_2, d_1 = \\beta_3 $$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Find a cubic polynomial\n",
    "$$f_2(x)= a_2 +b_2x+c_2x^2 +d_2x^3 $$\n",
    "#### such that $f(x) = f_2(x)$ for all $x > \\xi$. Express $a_2$,$b_2$,$c_2$,$d_2$ in terms of $\\beta_0$,$\\beta_1$,$\\beta_2$, $\\beta_3$,$\\beta_4$. We have now established that $f(x)$ is a piecewise polynomial. \n",
    "\n",
    "We can expand the $\\beta_4$ term to show that: $[x - \\xi]^3 = x^3 - \\xi^3 +3x\\xi^2 - 3x^2\\xi $\n",
    "Thus we can show that:\n",
    "$$ d_2 = (\\beta_3 + \\beta_4) $$\n",
    "$$ c_2 = (\\beta_2 - 3\\beta_4\\xi) $$\n",
    "$$ b_2 = (\\beta_1 + 3\\beta_4\\xi^2) $$\n",
    "$$ a_2 = (\\beta_0 -\\beta_4\\xi^3) $$\n",
    "This the function $f_2(x)$ is defined:\n",
    "$$ f_2(x) = (\\beta_0 -\\beta_4\\xi^3) +  (\\beta_1 + 3\\beta_4\\xi^2)x + (\\beta_2 - 3\\beta_4\\xi)x^2 + (\\beta_3 + \\beta_4)x^3 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Show that $f_1(\\xi) = f_2(\\xi)$. That is, $f(x)$ is continuous at $\\xi$. \n",
    "We can evaluate both functions at $x = \\xi$ , which forces the evauation of $[x - \\xi]^3$ to go to zero, thus both functions meet where $x = \\xi$ which allows the polynomail to be peice-wise defined as well as continuous over the given interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 [25%] \n",
    "### Use linear, cubic, and natural regression splines investigated Chapter 7 of ISL to the \"Auto\" data set. Is there evidence for non-linear relationships in this data set? Create some informative plots to justify your answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autodata = pd.read_csv('auto.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 [25%] \n",
    "### You will now derive the Bayesian connection to the lasso as discussed in Section 6.2.2. of ISL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Suppose that $y_i = \\beta_0 +\\sum_{j=1}^{p} x_{ij}\\beta_j \\epsilon_i$ where $\\epsilon_1 , ... , \\epsilon_n $ are independent and identically distributed from a normal distribution $N(0,1)$. Write out the likelihood for the data as a function of values $\\beta$.\n",
    "\n",
    "Likihood function is given in ISL, eqn. (4.5):\n",
    "$$ l(\\beta_0,\\beta_1) = \\prod_{i:y_i=1}p(x_i) \\prod_{i':y_{i'}=0}(1-p(x_{i'})) $$\n",
    "Where $p(x)$ is the logisitic function:\n",
    "$$ p(X) = \\frac{e^{\\beta_0+\\beta_1X}}{1+e^{\\beta_0+\\beta_1X}} $$\n",
    "Thus we can re-write the likihood function for the Gaussian as:\n",
    "$$ \\frac{1}{(2\\pi)^{n/2}}\\prod_{i=0}^{n}e^{-\\frac{\\epsilon^2_i}{2}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4 [25%] \n",
    "### Based on a true story, according to: The Drunkard’s Walk: How Randomness Rules Our Lives, Leonard Mlodinow Suppose that you applied for a life insurance and underwent a physical exam. The bad news is that your application was rejected because you tested positive for HIV. The test’s sensitivity is 99.7% and speciﬁcity is 98.5% \n",
    "#### [https://en.wikipedia.org/wiki/Diagnosis_of_HIV/AIDS#Accuracy_of_HIV_testing]. \n",
    "### However, after studying the CDC website, you ﬁnd that in your ethnic group (age, gender, race, ...) only one in 10,000 people is infected. What is the probability that you actually have HIV?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity:\n",
    "$$ Sens = \\frac{TP}{TP+FN} $$\n",
    "Specificity:\n",
    "$$ Spec = \\frac{TN}{TN + FP} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity the ratio of correct diagnoses to the total revelent cases. It is the case of how many correct idenfications that there are. Thus, this score tells me that the test has a 99.7% chance of correctly identifying a case. Specificity is the ratio of correct passes to the total number of passes of the test. This score tells me that the test has a 98.5% chance of correctly identifying not having a case correctly. \\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
