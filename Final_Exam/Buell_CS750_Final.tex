% ================
% Landon Buell
% Marek Petrik
% CS 750.01
% 8 May 2020
% ================

\documentclass[12pt,letterpaper]{article}

\usepackage[left=2.5cm,right=2.5cm,top=2.5cm]{geometry}
\usepackage{amsmath}
\usepackage{fancyhdr}

% ================================================================

\pagestyle{fancy}
\fancyhf{}
\lhead{CS750-Final Exam}
\rhead{Landon Buell}
\cfoot{\thepage}

\begin{document}

% ================================================================

\title{Introduction to Machine Learning - Final Exam}
\date{Spring 2020}
\author{Landon Buell}
\maketitle

% ================================================================

\section*{Problem 1}
Assume that you have a data set with a predictor (feature) $X$ and the target $Y$. You run simple linear regression ($Y ~ X$) and get the best fit with RSS=20 and TSS=120.\\

\textbf{1. What is the covariance between X and Y if the variances of X and Y are Var(X)=15 and Var(Y)=20?}
\paragraph*{}The \textit{covariance} between variables $X$ and $Y$ is defined by:
\begin{equation}
\label{covar}
Cov(X,Y) = E[XY] + E[X]E[Y]
\end{equation}

\textbf{2. Repeat if RSS=50 and TSS=40. Discuss the result.}

% ================================================================

\section*{Problem 2}
Suppose that we estimate the regression coefficients in a LASSO model by solving:
\begin{equation}
\label{lasso}
\min_{\beta_0,...,\beta_p} \sum_{i=1}^{n} \Bigg( y_i - \beta_0 - \sum_{j=1}^{p}\beta_{j}x_{ij} \Bigg)^2 +
\frac{1}{\lambda} \sum_{j=1}^{p} |\beta_j|
\end{equation}
for a particular value of $\lambda$. For parts (1) through (5), indicate which of i. through v. is correct. Justify your answer.\\

\textbf{1. As we increase $\lambda$ from $0.1$ to $\infty$, the training RSS will typically:}
\paragraph*{}

\textbf{2. As we increase $\lambda$ from $0.1$ to $\infty$, the test MSE will typically:}
\paragraph*{}

\textbf{3. As we increase $\lambda$ from $0.1$ to $\infty$, the (squared bias) will typically:}
\paragraph*{}

\textbf{4. As we increase $\lambda$ from $0.1$ to $\infty$, the variance will typically:}
\paragraph*{}

\textbf{5. As we increase $\lambda$ from $0.1$ to $\infty$, the irreducible error will typically:}
\paragraph*{}

\textbf{6. How would I choose the best value for $\lambda$?}
\paragraph*{}There is no single rule for what $\lambda$ works best for any given problem, thus I would have to implement some sort of \textit{cross-validation} method. I would essentially choose a subset of values to test, construct a LASSO model with each value, and then choose the $\lambda$ that results in the lowest testing RSS error.

% ================================================================

\section*{Problem 3}

\textbf{1. Do you expect random forests to achieve a smaller or larger training error than bagged trees with the same number of trees? Justify your answer.}


\textbf{2. How would you expect the training error of bagged trees to compare with boosted trees? Justify your answer.}


\textbf{3. How would you decide how many trees to use for any particular data set in a random forest? It is best to choose the number that minimizes the training error? Why or why not?}

% ================================================================

\section*{Problem 4}
This problem examines the differences between SVC (linear SVM), SVM with a polynomial kernel, and other linear classifiers. \\

\textbf{1. For an arbitrary training set, would you expect for SVC (linear) or SVM (polynomial kernel) to work better on the training set? Why?}
\paragraph*{}For any given data set, I would predict that a polynomial kernel SVM would work better on a training set. By design, a linear Support Vector Classifier, as the name implies, uses linear support vectors to create it's decision boundary. This model will only have a low training and testing error is the decision boundary between features is linear or can be approximated as linear. In most real-world data sets do not have linear decision boundaries.
\paragraph*{}On the other hand, a polynomial kernel Support Vector Machine, is built off of polynomial decision boundaries. Adding more terms and features is guaranteed to decrease the training error, but not necessarily the test error. Furthermore, In some cases, features with almost-linear decision boundary can be approximated with a polynomial where higher degrees have extremely small coefficients (Almost like Taylor-Series). In this cases, a polynomial kernel would still perform well on a linearly separable data set.\\

\textbf{2. If the Bayes decision boundary between the two classes is linear, would you expect SVC or SVM to work better on the training set?}
\paragraph*{}If we know the decision boundary is linear, then a SVC

\textbf{3. True or False: There is no need to use slack variables in SVMs with polynomial kernels because the decision boundary can be nonlinear. Justify your answer.}


\textbf{4. LDA, Logistic regression, and SVC (linear) all fit a linear decision boundary. Will their fits be the same? What would be some reasons for you to prefer LDA over SVC?}


% ================================================================

\section*{Problem 5}


% ================================================================


\end{document}